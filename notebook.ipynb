{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Jupyter Notebook\n",
    "\n",
    "This notebook provides an explanation of our code. First we had to import some important packages such as numpy, pandas, sklearn that'd needed to read the parquet file content and build our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import sys\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import f_classif, SelectKBest\n",
    "from sklearn.model_selection import cross_val_score, KFold, LeaveOneOut, train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define some constants such the scaler variable to scale the data and the path to the original parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "DATA_PATH = \"trots_2013-2022.parquet\"\n",
    "scale = StandardScaler()\n",
    "horseCount = {} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotValues(df):\n",
    "    # plt.figure(figsize=(8, 6))\n",
    "\n",
    "    # Adding jitter to better visualize overlapping points\n",
    "    sns.stripplot(x='FrontHindShoes', y='BeatenMargin', data=df, jitter=True, palette='viridis')\n",
    "\n",
    "    # Optionally, you can use a violin plot for better distribution visualization\n",
    "    # sns.violinplot(x='Category', y='Numeric_Output', data=df, inner='quartile', palette='viridis')\n",
    "\n",
    "    plt.title('Scatter Plot of Categorical Input vs. Numeric Output')\n",
    "    plt.xlabel('FrontHindShoes')\n",
    "    plt.ylabel('BeatenMargin')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def mapFinish(x):\n",
    "    val = x.strip()\n",
    "    if x.strip().isnumeric(): return int(x)\n",
    "    elif val=='BS': return -1\n",
    "    elif val=='UN': return -2\n",
    "    elif val=='DQ': return -3\n",
    "    elif val=='PU': return -4\n",
    "    elif val=='NP': return -5\n",
    "    elif val=='FL': return -6\n",
    "    elif val=='UR': return -7\n",
    "    elif val=='WC': return -8\n",
    "\n",
    "def mapFinishBinary(x):\n",
    "    if x.strip() == '1' :return 1\n",
    "    else: return 0\n",
    "\n",
    "def strToDate(str):\n",
    "    return str.date()\n",
    "\n",
    "def logit2prob(logr, X):\n",
    "  log_odds = logr.coef_ * X + logr.intercept_\n",
    "  odds = numpy.exp(log_odds)\n",
    "  probability = odds / (1 + odds)\n",
    "  return(probability)\n",
    "\n",
    "def evaluateWithConfusionMatrix(actual, predicted):\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(actual, predicted, labels=actual.unique())\n",
    "\n",
    "    cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = actual.unique())\n",
    "\n",
    "    cm_display.plot()\n",
    "    plt.show()\n",
    "\n",
    "def scaleDf(orgDf, columnsToScale, otherAttr):\n",
    "    scaled_data = scale.fit_transform(orgDf[columnsToScale])\n",
    "\n",
    "    # # Create a new DataFrame with scaled values\n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=columnsToScale)\n",
    "    # print(trainingSet)\n",
    "    # # Combine the scaled numeric columns with the non-numeric columns\n",
    "    df_scaled = pd.concat([scaled_df, orgDf[otherAttr].reset_index(drop=True)],\n",
    "                           ignore_index=True, sort=False, axis=1)\n",
    "    return df_scaled\n",
    "\n",
    "def crossValidateModel(model, X, y, cv_technique):\n",
    "    scores = cross_val_score(model, X, y, cv = cv_technique)\n",
    "    print(\"Cross Validation Scores: \", scores)\n",
    "    print(\"Average CV Score: \", scores.mean())\n",
    "    print(\"Number of CV Scores used in Average: \", len(scores))\n",
    "\n",
    "def countNumberOfHorsesPerRace(df):\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        id = row['RaceID']\n",
    "        horseCount[id] = horseCount.get(id, 0) + 1\n",
    "\n",
    "def addHorseCount(raceId):\n",
    "    return horseCount.get(raceId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "Finally this is our logistic regression that has been built and to do we had to do some feature engineering by one hot encoding the data\n",
    "building a new column, number of horses that could help in classifying the horses in the race. We also had to split the  data into\n",
    "training and testing sets based on the race date. When the logistic regression model was built we use the probability of the win class in the \n",
    "regression and built a data frame that'd be converted to a parquet file later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    FILTER_DATE = datetime.date(2021, 11, 1)\n",
    "    k_folds = KFold(n_splits=5)\n",
    "\n",
    "    k_best = SelectKBest(score_func=f_classif, k='all')\n",
    "\n",
    "    outPutDf = pd.DataFrame(columns=[\"Winprob\"])\n",
    "\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "\n",
    "    df = pd.get_dummies(df, columns=[\"AgeRestriction\", \"CourseIndicator\",  \"GoingAbbrev\", \"HandicapType\", \"RaceGroup\",\n",
    "                                      \"RacingSubType\",\"SexRestriction\",\n",
    "                                      \"StartType\", \"Surface\"],\n",
    "                         dtype=int, drop_first=True)\n",
    "    countNumberOfHorsesPerRace(df)\n",
    "    df[\"FinishPosition\"] = df[\"FinishPosition\"].apply(mapFinishBinary)\n",
    "    df[\"NumberOfHorses\"] = df[\"RaceID\"].apply(addHorseCount)\n",
    "    df[\"FrontHindShoes\"] = df[\"FrontShoes\"].astype(str) + df[\"HindShoes\"].astype(str)\n",
    "    # df[\"JockeyID\"] = df[\"JockeyID\"].apply(hashId)\n",
    "\n",
    "    startTimeSeries = df[\"RaceStartTime\"].apply(strToDate)\n",
    "    trainingSet = df.loc[startTimeSeries < FILTER_DATE]\n",
    "    # trainingSet, validateSet = train_test_split(df.loc[startTimeSeries < FILTER_DATE], test_size=0.2)\n",
    "    testSet = df.loc[startTimeSeries >= FILTER_DATE]\n",
    "    \n",
    "    # plotValues(trainingSet.iloc[:, :500][[\"HorseID\", \"RaceOverallTime\"]])\n",
    "    # print(df.columns)\n",
    "\n",
    "    columns_to_scale = [\"Distance\", 'HandicapDistance', 'WeightCarried']\n",
    "\n",
    "    trainingAttr = ['Barrier', 'GoingAbbrev_H  ', 'GoingAbbrev_SO ', 'GoingAbbrev_U  ',\n",
    "                    'GoingAbbrev_VF ', \"FrontShoes\", \"HandicapType_Cwt\", \"HandicapType_Hcp\", \n",
    "                     \"HorseAge\", \"HindShoes\",  \"RaceGroup_G1\", \n",
    "                    \"RaceGroup_G2\", \"RaceGroup_G3\",'SexRestriction_C&G', 'SexRestriction_F',\n",
    "                    'SexRestriction_M',  \"StartType_V\", \"StartingLine\", \n",
    "                    \"Surface_S\", \"Surface_T\", \"WetnessScale\", 'AgeRestriction_2yo',\n",
    "       'AgeRestriction_3-10yo', 'AgeRestriction_3-5yo', 'AgeRestriction_3yo',\n",
    "       'AgeRestriction_3yo+', 'AgeRestriction_4&5yo', 'AgeRestriction_4-10yo',\n",
    "       'AgeRestriction_4-6yo', 'AgeRestriction_4-7yo', 'AgeRestriction_4-8yo',\n",
    "       'AgeRestriction_4-9yo', 'AgeRestriction_4yo', 'AgeRestriction_4yo+',\n",
    "       'AgeRestriction_5&6yo', 'AgeRestriction_5-10yo', 'AgeRestriction_5-7yo',\n",
    "       'AgeRestriction_5-8yo', 'AgeRestriction_5-9yo', 'AgeRestriction_5yo',\n",
    "       'AgeRestriction_5yo+', 'AgeRestriction_6&7yo', 'AgeRestriction_6-10yo',\n",
    "       'AgeRestriction_6-8yo', 'AgeRestriction_6-9yo', 'AgeRestriction_6yo',\n",
    "       'AgeRestriction_6yo+', 'AgeRestriction_7&8yo', 'AgeRestriction_7-10yo',\n",
    "       'AgeRestriction_7-9yo', 'AgeRestriction_7yo', 'AgeRestriction_7yo+',\n",
    "       'AgeRestriction_8&9yo', 'AgeRestriction_8-10yo', 'AgeRestriction_8yo',\n",
    "       'AgeRestriction_8yo+', 'AgeRestriction_9&10yo', 'AgeRestriction_Pour 9', 'NumberOfHorses', 'RaceID',\n",
    "       'HorseID', 'TrainerID', 'JockeyID', 'TrackID', 'CourseIndicator_&', 'CourseIndicator_G', 'CourseIndicator_P',\n",
    "       'RacePrizemoney']\n",
    "\n",
    "    targetAttr = [\"FinishPosition\"]\n",
    "\n",
    "    # X_train_best = k_best.fit_transform(trainingSet[trainingAttr], trainingSet[targetAttr])\n",
    "\n",
    "    # selected_features_indices = k_best.get_support(indices=True)\n",
    "\n",
    "    # # Get feature names\n",
    "    # selected_feature_names = trainingSet[trainingAttr].columns[selected_features_indices]\n",
    "\n",
    "    # for feature_name, score, p_value in zip(selected_feature_names, k_best.scores_, k_best.pvalues_):\n",
    "    #     print(f\"Feature: {feature_name}, Score: {score}, P-value: {p_value}\")\n",
    "\n",
    "    # sampleTestData = testSet[testSet[\"RaceID\"]==1682989]\n",
    "    \n",
    "\n",
    "    # print(df[trainingAttr].corr(method ='pearson')['RaceOverallTime'].to_string())\n",
    "    # print(df['NumberOfHorses'].unique())\n",
    "    X_train = scaleDf(trainingSet, columns_to_scale, trainingAttr)\n",
    "    y_train = trainingSet[targetAttr]\n",
    "    \n",
    "    # scaled_data = scale.fit_transform(trainingSet[columns_to_scale])\n",
    "\n",
    "    # print(trainingSet)\n",
    "    logr = linear_model.LogisticRegression(max_iter=4000)\n",
    "    logr.fit(X_train, y_train.values.ravel())\n",
    "    X_test = scaleDf(testSet, columns_to_scale, trainingAttr)\n",
    "    y_true = testSet[targetAttr]\n",
    "    y_pred = logr.predict(X_test.to_numpy())\n",
    "\n",
    "\n",
    "    \n",
    "    probaFromTrain = logr.predict_proba(X_train)\n",
    "    probaFromTest = logr.predict_proba(X_test)\n",
    "    combined = numpy.vstack((probaFromTrain, probaFromTest))\n",
    "    \n",
    "    outPutDf = pd.DataFrame(combined, columns=['NotWin', 'Win'])[['Win']]\n",
    "\n",
    "\n",
    "    # print(testSet[['RaceID', 'FinishPosition']][:20])\n",
    "    # print('--------------------------------')\n",
    "    # print(y_true[:20])\n",
    "    # print('--------------------------------')\n",
    "    # print(y_pred[:20])\n",
    "    # print(logr.coef_)\n",
    "    # for index, row in X_train.iterrows():\n",
    "        # print(row.to_numpy())\n",
    "    # logit2prob(logr, X_train)\n",
    "\n",
    "    # print(logr.score(X_train, y_train))\n",
    "\n",
    "    # crossValidateModel(logr, X_train, y_train.values.ravel(), k_folds)\n",
    "    # evaluateWithConfusionMatrix(y_true, y_pred)\n",
    "    # print(classification_report(y_true, y_pred))\n",
    "\n",
    "\n",
    "    # knn = KNeighborsClassifier(n_neighbors=5)\n",
    "    # knn.fit(X_train, y_train.values.ravel())\n",
    "    # y_pred = knn.predict(X_test)\n",
    "    # print(y_true.to_numpy()[:80])\n",
    "    # print(\"-------------------------------------------------------------\")\n",
    "    # print(y_pred[:80])\n",
    "    # # precision ratio: tp / (tp + fp), aiming at minimize fp (predict: win, actual: lose)\n",
    "    # print(precision_score(y_true, y_pred, average='weighted'))\n",
    "    # print(classification_report(y_true, y_pred))\n",
    "    # scores[13] = ps\n",
    "    # scores_list.append(ps)\n",
    "    \n",
    "    # print(scores)\n",
    "    # print(max(scores_list))\n",
    "\n",
    "    # y_pred = logr.predict(testSet[trainingAttr].to_numpy())\n",
    "\n",
    "    # regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "    # # Train the regressor on the training data\n",
    "    # regressor.fit(trainingSet[trainingAttr], trainingSet[targetAttr])\n",
    "\n",
    "    # # Make predictions on the test set\n",
    "    # y_pred = regressor.predict(testSet[trainingAttr])\n",
    "\n",
    "    # # Evaluate the model using mean squared error\n",
    "    # mse = mean_squared_error(testSet[targetAttr].to_numpy(), y_pred)\n",
    "    # print(\"Mean Squared Error:\", mse)\n",
    "    outPutDf.to_parquet('output.parquet')\n",
    "\n",
    "\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
